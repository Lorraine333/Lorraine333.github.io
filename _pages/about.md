---
permalink: /
title:	
excerpt: About me
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I'm an assistant professor in the [Department of Computer Science](https://www.cs.pitt.edu/) at the University of Pittsburgh. I'm also affiliated with the [ISP program](https://www.isp.pitt.edu/about) at [SCI](https://www.sci.pitt.edu/). Me and my students actively maintain the [Pitt NLP Seminar](https://pitt-nlp-seminar.github.io/pitt_nlp_seminar_2024/).

**My research interests** are at the intersection of natural language processing and machine learning. In particular, I'm interested in
1. Understand model behavior via evaluation benchmark design and exploration around the meaning of model parameters in complex or long-tail situations.
2. Understand and evaluate models' ability to perform complex reasoning using atomic knowledge articles. 
3. I'm interested in applying current LLM techniques in high-impact domains, such as law and education, to study the model's behavior and limitations.
My overall research goal is to construct socially responsible, equitable, and robust models that cater to diverse users, populations, cultures, and scenarios.

**Prospective Students**: 

- Pitt Students
Please fill in this [form](https://forms.gle/1YUhvYUXn5kSRQw17), specifying your past experiences, and your research interest. We will contact you if there is an oppotunity open.
- Non-Pitt Students
Please apply through the Pitt CS or ISP PhD program and mention my name. Unfortunately, I won't be able to answer individual emails. 

**News**:
- 2025.08: *Our paper "Resolving UnderEdit & OverEdit with Iterative & Neighbor-Assisted Model Editing." is accepted to EMNLP Findings 2025.*
- 2025.08: *Our paper "Think Globally, Group Locally: Evaluating LLMs Using Multi-Lingual Word Grouping Games." is accepted to EMNLP Main 2025.*
- 2025.08: *Our paper "Leveraging Large Models for Evaluating Novel Content: A Case Study on Advertisement Creativity." is accepted to EMNLP Main 2025.*
- 2025.05: *Our paper "Unveiling Confirmation Bias in Chain-of-Thought Reasoning." is accepted to ACL Findings 2025.*
- 2025.04: *Gave keynote talk at [MASC-SLL](https://www.mascsll.org/) 2025.*
- 2024.12: *Cesar was selected as an Honorable Mention for the 2024-2025 Outstanding Undergraduate Researcher Award. Congrats Cesar!*
- 2024.12: *Selected for the [AAAI New Faculty Highlights Program](https://aaai.org/conference/aaai/aaai-25/new-faculty-highlights-program/) 2025.*
- 2024.12: *Our paper "Improve LLM-based Automatic Essay Scoring with Linguistic Features." is accepted to AAAI iRAISE 2025 as a spotlight paper.*
- 2024.09: *Our paper "Persuasiveness of Generated Free-Text Rationales in Subjective Decisions: A Case Study on Pairwise Argument Ranking." is accepted to EMNLP Findings 2024.*
- 2024.09: *Our paper "In Search of the Long-Tail: Systematic Generation of Long-Tail Inferential Knowledge via Logical Rule Guided Search." is accepted to EMNLP 2024.*
- 2024.05: *Our paper "Every Answer Matters: Evaluating Commonsense with Probabilistic Measures" is accepted to ACL 2024.*
- 2024.03: *Received funding from Pitt Cyber. Thanks, Pitt Cyber!*
- 2024.03: *Our proposed symposium MAKE is happening at Stanford University as part of the 2024 AAAI Spring Symposium Series.*
- 2024.03: *Our paper "UNcommonsense Reasoning: Abductive Reasoning about Uncommon Situations" is accepted to NAACL 2024.*
- 2024.02: *Our paper "Incorporating Geo-Diverse Knowledge into Prompting for Increased Geographical Robustness in Object Recognition" is accepted to CVPR 2024.*
- 2024.01: *Our paper "PlaSma: Making Small Language Models Better Procedural Knowledge Models for (Counterfactual) Planning" is accepted to ICLR 2024.*
- 2023.10: *Our paper "Editing Commonsense Knowledge in GPT." is accepted to EMNLP 2023.*
- 2023.09: *Our paper "Faith and Fate: Limits of Transformers on Compositionality" is accepted as a spotlight paper at NeurIPS 2023!*
- 2023.09: *I started a tenure track AP position at Pitt.*


**Past Experiences:** Before joining Pitt, I spend one year as a young investigator work with the [AI2 Mosaic team](https://mosaic.allenai.org/). I defended my PhD at [UMass Amherst](https://www.cics.umass.edu/) working in [IESL](http://www.iesl.cs.umass.edu/) with my advisor [Andrew McCallum](http://people.cs.umass.edu/~mccallum/) in August 2022. During the summer of 2017 and 2018, I worked at Google Mountain View on knowledge graphs, focusing on hierarchical relationships. I spent the summer of 2019 working with the [Bloomberg Data Science Team](https://www.techatbloomberg.com/post-topic/data-science/) on generating test cases for programs with seq2seq models. In 2020, I finished a remote internship at [Meta AI Research](https://ai.facebook.com/), where I focused on multi-hop question answering. Furthermore, I had the opportunity to work remotely with the [DeepMind](https://deepmind.com/) Language Team in 2021, trying to understand commonsense in large language models.
