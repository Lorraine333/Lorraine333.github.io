I'm an assistant professor in the [Department of Computer Science](https://www.cs.pitt.edu/) at the University of Pittsburgh. I'm also affiliated with the [ISP program](https://www.isp.pitt.edu/about) at [SCI](https://www.sci.pitt.edu/). Before joining Pitt, I spend one year as a young investigator work with the [AI2 Mosaic team](https://mosaic.allenai.org/). I defended my PhD at [UMass Amherst](https://www.cics.umass.edu/) working in [IESL](http://www.iesl.cs.umass.edu/) with my advisor [Andrew McCallum](http://people.cs.umass.edu/~mccallum/)in August 2022.

**My research interests** are at the intersection of natural language processing and machine learning. In particular, I'm interested in
1. Understanding model behavior via evaluation benchmark design and exploration around the meaning of model parameters in complex or long-tail situations.
2. Understand and evaluate models' ability to perform complex reasoning using atomic knowledge articles. 
3. I'm interested in applying current LLM techniques in high-impact domains such as law and education.
My overall research goal is to construct socially responsible, equitable, and robust models that cater to diverse users, populations, cultures, and scenarios.

**Prospective graduate students**: Please apply through the Pitt CS or ISP PhD program and mention my name. Unfortunately, I won't be able to answer individual emails. 
**Prospective students at Pitt**: Please fill in this [form](https://forms.gle/1YUhvYUXn5kSRQw17), specifying your past experiences, and your research interest. We will contact you if there is an oppotunity open.

**Industry Experience:** During the summer of 2017 and 2018, I worked at Google Mountain View on knowledge graphs, focusing on hierarchical relationships. I spent the summer of 2019 working with the [Bloomberg Data Science Team](https://www.techatbloomberg.com/post-topic/data-science/) on generating test cases for programs with seq2seq models. In 2020, I finished a remote internship at [Meta AI Research](https://ai.facebook.com/), where I focused on multi-hop question answering. Furthermore, I had the opportunity to work remotely with the [DeepMind](https://deepmind.com/) Language Team in 2021, trying to understand commonsense in large language models.
